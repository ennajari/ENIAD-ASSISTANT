{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4387f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI, HuggingFaceHub\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from transformers import pipeline\n",
    "from translate import Translator\n",
    "import logging\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from fuzzywuzzy import fuzz\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bee147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données JSON (50 questions/réponses)\n",
    "qa_data = [\n",
    "    {\"question\": \"Quels sont les horaires d'ouverture de la bibliothèque de l'ENIAD Berkane ?\", \"réponse\": \"La bibliothèque est ouverte de 8h à 20h du lundi au vendredi, et de 9h à 17h le samedi.\"},\n",
    "    {\"question\": \"Comment s'inscrire à un cours d'intelligence artificielle ?\", \"réponse\": \"L'inscription se fait en ligne via le portail étudiant ou au bureau des admissions de l'ENIAD.\"},\n",
    "    {\"question\": \"Où se trouve le campus de l'ENIAD Berkane ?\", \"réponse\": \"Le campus est situé à Berkane, près de l'Université Mohammed 1er, dans la région de l'Oriental.\"},\n",
    "    {\"question\": \"Quelles sont les filières proposées à l'ENIAD ?\", \"réponse\": \"L'ENIAD propose des filières en IA, Robotique, Sécurité Informatique et Génie Informatique.\"},\n",
    "    {\"question\": \"Quel est le coût des frais de scolarité ?\", \"réponse\": \"Les frais varient selon le programme ; contactez l'administration pour plus de détails.\"},\n",
    "    {\"question\": \"Y a-t-il un internat à l'ENIAD Berkane ?\", \"réponse\": \"Non, l'ENIAD ne dispose pas d'internat, mais des logements privés sont disponibles à proximité.\"},\n",
    "    {\"question\": \"Comment contacter un professeur ?\", \"réponse\": \"Les coordonnées des professeurs sont disponibles sur le portail étudiant ou au secrétariat.\"},\n",
    "    {\"question\": \"Quand commence l'année scolaire 2025-2026 ?\", \"réponse\": \"L'année scolaire débute généralement en septembre, vérifiez les dates exactes sur le site officiel.\"},\n",
    "    {\"question\": \"Quels sont les prérequis pour le cycle ingénieur ?\", \"réponse\": \"Un diplôme de niveau bac+2 ou équivalent dans une filière technique est requis.\"},\n",
    "    {\"question\": \"L'ENIAD offre-t-elle des formations en ligne ?\", \"réponse\": \"Oui, certaines formations courtes sont disponibles en ligne via la plateforme e-learning.\"},\n",
    "    {\"question\": \"Comment accéder au Wi-Fi du campus ?\", \"réponse\": \"Utilisez votre identifiant étudiant et mot de passe fournis à l'inscription.\"},\n",
    "    {\"question\": \"Quels logiciels sont utilisés en cours d'IA ?\", \"réponse\": \"Python, TensorFlow, PyTorch et d'autres outils sont couramment utilisés.\"},\n",
    "    {\"question\": \"Y a-t-il des stages obligatoires ?\", \"réponse\": \"Oui, un stage est requis en fin de cycle pour valider le diplôme d'ingénieur.\"},\n",
    "    {\"question\": \"Où puis-je trouver le calendrier des examens ?\", \"réponse\": \"Le calendrier est publié sur le portail étudiant au début de chaque semestre.\"},\n",
    "    {\"question\": \"L'ENIAD organise-t-elle des événements ?\", \"réponse\": \"Oui, des hackathons, conférences et ateliers sont régulièrement organisés.\"},\n",
    "    {\"question\": \"Comment demander une bourse ?\", \"réponse\": \"Soumettez une demande via le portail étudiant avant la date limite annuelle.\"},\n",
    "    {\"question\": \"Quels sont les débouchés après un diplôme de l'ENIAD ?\", \"réponse\": \"Les diplômés travaillent dans l'IA, la cybersécurité, le développement logiciel, etc.\"},\n",
    "    {\"question\": \"Y a-t-il un club de robotique ?\", \"réponse\": \"Oui, le club de robotique est ouvert à tous les étudiants intéressés.\"},\n",
    "    {\"question\": \"Comment réserver une salle de travail ?\", \"réponse\": \"Les réservations se font via l'application interne de l'ENIAD.\"},\n",
    "    {\"question\": \"Quels sont les horaires des cours ?\", \"réponse\": \"Les cours ont lieu généralement de 8h30 à 17h, selon l'emploi du temps.\"},\n",
    "    {\"question\": \"L'ENIAD a-t-elle un partenariat avec des entreprises ?\", \"réponse\": \"Oui, elle collabore avec des entreprises technologiques pour des projets et stages.\"},\n",
    "    {\"question\": \"Comment assister à une journée portes ouvertes ?\", \"réponse\": \"Les dates sont annoncées sur le site officiel ; l'inscription est souvent requise.\"},\n",
    "    {\"question\": \"Quels sont les documents pour l'inscription ?\", \"réponse\": \"Carte d'identité, diplômes, relevés de notes et photos d'identité sont nécessaires.\"},\n",
    "    {\"question\": \"Y a-t-il des cours en anglais ?\", \"réponse\": \"Oui, certains modules avancés sont dispensés en anglais.\"},\n",
    "    {\"question\": \"Comment signaler un problème technique ?\", \"réponse\": \"Contactez le support informatique via l'adresse email support@eniad.ump.ma.\"},\n",
    "    {\"question\": \"L'ENIAD propose-t-elle des certifications ?\", \"réponse\": \"Oui, des certifications en IA et cybersécurité sont disponibles.\"},\n",
    "    {\"question\": \"Où manger sur le campus ?\", \"réponse\": \"Une cafétéria est disponible, mais il n'y a pas de restaurant universitaire.\"},\n",
    "    {\"question\": \"Comment participer à un projet de recherche ?\", \"réponse\": \"Contactez les professeurs ou le département de recherche de l'ENIAD.\"},\n",
    "    {\"question\": \"Quels sont les délais pour payer les frais ?\", \"réponse\": \"Les frais doivent être payés avant le début de chaque semestre.\"},\n",
    "    {\"question\": \"L'ENIAD a-t-elle une bibliothèque numérique ?\", \"réponse\": \"Oui, une bibliothèque numérique est accessible avec vos identifiants étudiants.\"},\n",
    "    {\"question\": \"Qu'est-ce que le Big Data à l'ENIAD Berkane ?\", \"réponse\": \"Le Big Data à l'ENIAD couvre l'analyse de grandes quantités de données avec des outils comme Hadoop et Spark.\"},\n",
    "    {\"question\": \"Quels outils de Big Data sont enseignés ?\", \"réponse\": \"Hadoop, Apache Spark, Kafka et des bases de données NoSQL comme MongoDB sont au programme.\"},\n",
    "    {\"question\": \"Comment s'inscrire au module Big Data ?\", \"réponse\": \"Inscrivez-vous via le portail étudiant ou consultez le responsable du département IA.\"},\n",
    "    {\"question\": \"Y a-t-il des projets Big Data à l'ENIAD ?\", \"réponse\": \"Oui, les étudiants travaillent sur des projets réels avec des entreprises partenaires.\"},\n",
    "    {\"question\": \"Quelles sont les bases de données utilisées en Big Data ?\", \"réponse\": \"Les bases vectorielles, MongoDB, et Cassandra sont souvent utilisées.\"},\n",
    "    {\"question\": \"Comment accéder aux serveurs Big Data ?\", \"réponse\": \"Les serveurs sont accessibles via une connexion sécurisée avec vos identifiants étudiants.\"},\n",
    "    {\"question\": \"Le Big Data est-il obligatoire à l'ENIAD ?\", \"réponse\": \"Non, mais il est fortement recommandé pour les spécialisations en IA et informatique.\"},\n",
    "    {\"question\": \"Quels sont les prérequis pour le cours de Big Data ?\", \"réponse\": \"Des bases en programmation (Python) et en bases de données sont nécessaires.\"},\n",
    "    {\"question\": \"Y a-t-il des certifications en Big Data ?\", \"réponse\": \"Oui, l'ENIAD propose des certifications reconnues en partenariat avec des entreprises.\"},\n",
    "    {\"question\": \"Comment analyser des données massives à l'ENIAD ?\", \"réponse\": \"Utilisez les outils enseignés comme Spark ou participez aux ateliers pratiques.\"},\n",
    "    {\"question\": \"Quels sont les débouchés du Big Data ?\", \"réponse\": \"Data Scientist, Ingénieur Big Data, Analyste de données, etc.\"},\n",
    "    {\"question\": \"L'ENIAD a-t-elle un cluster Hadoop ?\", \"réponse\": \"Oui, un cluster Hadoop est disponible pour les projets étudiants.\"},\n",
    "    {\"question\": \"Comment participer à un hackathon Big Data ?\", \"réponse\": \"Inscrivez-vous aux événements annoncés sur le portail ou par email.\"},\n",
    "    {\"question\": \"Qu'est-ce qu'une base de données vectorielle ?\", \"réponse\": \"C'est une base optimisée pour les recherches rapides, utilisée dans le Big Data et l'IA.\"},\n",
    "    {\"question\": \"Le Big Data est-il enseigné en anglais ?\", \"réponse\": \"Oui, certains cours avancés sont en anglais pour attirer un public international.\"},\n",
    "    {\"question\": \"Comment stocker des données massives à l'ENIAD ?\", \"réponse\": \"Les données sont stockées sur des serveurs cloud ou locaux avec Hadoop HDFS.\"},\n",
    "    {\"question\": \"Y a-t-il des partenariats Big Data avec des entreprises ?\", \"réponse\": \"Oui, des collaborations existent avec des sociétés technologiques marocaines et internationales.\"},\n",
    "    {\"question\": \"Quels sont les projets Big Data en cours ?\", \"réponse\": \"Des projets sur l'analyse de données éducatives et industrielles sont en cours.\"},\n",
    "    {\"question\": \"Comment apprendre Apache Spark à l'ENIAD ?\", \"réponse\": \"Inscrivez-vous au module Big Data ou suivez les tutoriels en ligne de l'ENIAD.\"},\n",
    "    {\"question\": \"Le Big Data aide-t-il les étudiants à l'ENIAD ?\", \"réponse\": \"Oui, il permet d'analyser des données pour améliorer les services et l'enseignement.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    filename='eniad_assistant.log')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea783a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "try:\n",
    "    with open('data/questions_fr.json', 'r', encoding='utf-8') as f:\n",
    "        qa_data_fr = json.load(f)\n",
    "    \n",
    "    with open('data/questions_en.json', 'r', encoding='utf-8') as f:\n",
    "        qa_data_en = json.load(f)\n",
    "    \n",
    "    logger.info(\"Données chargées avec succès\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors du chargement des données: {e}\")\n",
    "    # Données de secours\n",
    "    qa_data_fr = [\n",
    "        {\"question\": \"Quels sont les horaires d'ouverture de la bibliothèque de l'ENIAD Berkane ?\", \n",
    "         \"réponse\": \"La bibliothèque est ouverte de 8h à 20h du lundi au vendredi, et de 9h à 17h le samedi.\"},\n",
    "        {\"question\": \"Comment puis-je m'inscrire à un club étudiant ?\", \n",
    "         \"réponse\": \"Pour vous inscrire à un club étudiant, rendez-vous au bureau de la vie étudiante avec votre carte d'étudiant ou visitez le portail en ligne des activités étudiantes.\"}\n",
    "    ]\n",
    "    qa_data_en = [\n",
    "        {\"question\": \"What are the opening hours of the ENIAD Berkane library?\", \n",
    "         \"answer\": \"The library is open from 8am to 8pm Monday to Friday, and from 9am to 5pm on Saturday.\"},\n",
    "        {\"question\": \"How can I join a student club?\", \n",
    "         \"answer\": \"To join a student club, go to the student life office with your student ID or visit the online student activities portal.\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la base de données vectorielle\n",
    "def initialize_vector_db():\n",
    "    try:\n",
    "        # Préparation des documents\n",
    "        documents_fr = [doc[\"question\"] + \" \" + doc[\"réponse\"] for doc in qa_data_fr]\n",
    "        documents_en = [doc[\"question\"] + \" \" + doc[\"answer\"] for doc in qa_data_en]\n",
    "        \n",
    "        all_documents = documents_fr + documents_en\n",
    "        \n",
    "        # Utilisation des embeddings de HuggingFace\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        \n",
    "        # Création de la base de données vectorielle\n",
    "        vector_db = FAISS.from_texts(all_documents, embeddings)\n",
    "        \n",
    "        logger.info(\"Base de données vectorielle initialisée avec succès\")\n",
    "        return vector_db\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'initialisation de la base de données vectorielle: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16744fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du modèle de langage\n",
    "def initialize_llm():\n",
    "    try:\n",
    "        # Pour l'usage en production, utilisez votre API OpenAI ou un autre modèle\n",
    "        # llm = OpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\")\n",
    "        \n",
    "        # Version alternative avec HuggingFace\n",
    "        llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "                            model_kwargs={\"temperature\": 0.7, \"max_length\": 512})\n",
    "        \n",
    "        logger.info(\"Modèle de langage initialisé avec succès\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'initialisation du modèle de langage: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036eeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la mémoire de conversation\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Initialisation des ressources\n",
    "vector_db = initialize_vector_db()\n",
    "llm = initialize_llm()\n",
    "\n",
    "# Création de la chaîne de conversation\n",
    "if vector_db and llm:\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vector_db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        memory=memory,\n",
    "        return_source_documents=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af924ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduction\n",
    "def translate_text(text, target_lang):\n",
    "    try:\n",
    "        translator = Translator(to_lang=target_lang)\n",
    "        return translator.translate(text)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la traduction: {e}\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf4bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:999\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     31\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     39\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reconnaissance d'entités nommées\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ner_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_entities\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:942\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    941\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 942\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    953\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:266\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m look_tf:\n\u001b[1;32m--> 266\u001b[0m     _class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTF\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marchitecture\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1956\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   1958\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\Abdel\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "# Reconnaissance d'entités nommées\n",
    "ner_pipeline = pipeline(\"ner\")\n",
    "def extract_entities(text):\n",
    "    try:\n",
    "        entities = ner_pipeline(text)\n",
    "        return entities\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'extraction d'entités: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14581ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
