#!/usr/bin/env python3
"""
Final test of the interface with correct port
"""

import requests
import json

def test_final_interface():
    """Test the interface on the correct port"""
    print("üéì FINAL INTERFACE TEST")
    print("=" * 50)
    
    # Test 1: Interface accessibility
    print("\n1Ô∏è‚É£ Testing Interface Server...")
    try:
        response = requests.get("http://localhost:5174", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Interface: Running on port 5174")
            print("   URL: http://localhost:5174")
        else:
            print(f"‚ùå Interface: Status {response.status_code}")
    except Exception as e:
        print(f"‚ùå Interface: Not available - {e}")
    
    # Test 2: SMA Service
    print("\n2Ô∏è‚É£ Testing SMA Service...")
    try:
        response = requests.get("http://localhost:8001/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print("‚úÖ SMA Service: Running")
            print(f"   Status: {data.get('status', 'unknown')}")
            print(f"   Gemini API: {data.get('gemini_api', 'unknown')}")
        else:
            print(f"‚ùå SMA Service: Status {response.status_code}")
    except Exception as e:
        print(f"‚ùå SMA Service: Not available - {e}")
    
    # Test 3: Complete workflow test
    print("\n3Ô∏è‚É£ Testing Complete Workflow...")
    try:
        # Step 1: SMA intelligent query
        sma_payload = {
            "query": "Quelles formations en intelligence artificielle sont disponibles √† ENIAD?",
            "language": "fr",
            "search_depth": "medium",
            "include_documents": True,
            "include_images": True,
            "max_results": 5
        }
        
        sma_response = requests.post(
            "http://localhost:8001/sma/intelligent-query",
            json=sma_payload,
            timeout=30
        )
        
        if sma_response.status_code == 200:
            sma_data = sma_response.json()
            print("‚úÖ SMA Query: Working")
            print(f"   Items found: {sma_data.get('total_items_found', 0)}")
            
            # Step 2: Create SMA results for chat
            sma_results = {
                "results": sma_data.get('results', []) or [
                    {
                        "title": "Formations IA - ENIAD",
                        "content": "L'√âcole Nationale de l'Intelligence Artificielle et du Digital propose des formations sp√©cialis√©es en IA.",
                        "source_url": "https://eniad.ump.ma/fr"
                    }
                ],
                "sources": sma_data.get('sources', []) or [
                    {"url": "https://eniad.ump.ma/fr", "title": "ENIAD"}
                ],
                "metadata": {"confidence": sma_data.get('confidence', 0.8)},
                "total_found": sma_data.get('total_items_found', 1)
            }
            
            # Step 3: Chat with context
            chat_payload = {
                "query": "Quelles formations en intelligence artificielle sont disponibles √† ENIAD?",
                "language": "fr",
                "sma_results": sma_results
            }
            
            chat_response = requests.post(
                "http://localhost:8001/sma/chat-with-context",
                json=chat_payload,
                timeout=30
            )
            
            if chat_response.status_code == 200:
                chat_data = chat_response.json()
                print("‚úÖ Chat with Context: Working")
                print(f"   Model: {chat_data.get('model', 'unknown')}")
                print(f"   Provider: {chat_data.get('provider', 'unknown')}")
                print(f"   Answer length: {len(chat_data.get('final_answer', ''))}")
                print(f"   Answer preview: {chat_data.get('final_answer', '')[:100]}...")
                
                return True
            else:
                print(f"‚ùå Chat with Context: Failed {chat_response.status_code}")
                return False
        else:
            print(f"‚ùå SMA Query: Failed {sma_response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå Workflow test error: {e}")
        return False

def main():
    """Run final test"""
    success = test_final_interface()
    
    print("\n" + "=" * 50)
    print("üìã FINAL TEST RESULTS")
    print("=" * 50)
    
    if success:
        print("\nüéâ ALL SYSTEMS WORKING!")
        print("\nüìã How to Use the Interface:")
        print("1. Open: http://localhost:5174")
        print("2. Look for the Model Selector above the input")
        print("3. Choose 'Gemini API' (recommended)")
        print("4. Click the SMA button (üîç) to activate web intelligence")
        print("5. Ask questions like:")
        print("   ‚Ä¢ 'Quelles formations en intelligence artificielle sont disponibles?'")
        print("   ‚Ä¢ 'Comment s'inscrire aux cours?'")
        print("   ‚Ä¢ 'ŸÖÿß ŸáŸä ÿßŸÑÿ®ÿ±ÿßŸÖÿ¨ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ŸÅŸä ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸäÿü'")
        
        print("\nüí° What You Should See:")
        print("‚Ä¢ Model selector with Gemini/Llama options")
        print("‚Ä¢ SMA button that toggles on/off")
        print("‚Ä¢ Intelligent responses with source citations")
        print("‚Ä¢ No 'D√©sol√©, une erreur est survenue' messages")
        
        print("\nüîß If You Still See Errors:")
        print("‚Ä¢ Open browser console (F12) and check for errors")
        print("‚Ä¢ Make sure you're using the correct URL: http://localhost:5174")
        print("‚Ä¢ Try refreshing the page")
        print("‚Ä¢ Try switching between models")
        
    else:
        print("\n‚ö†Ô∏è SOME ISSUES DETECTED")
        print("‚Ä¢ Check that SMA service is running: python main.py")
        print("‚Ä¢ Check that interface is running: npm run dev")
        print("‚Ä¢ Verify ports: Interface=5174, SMA=8001")
    
    print("\nüéØ Expected Interface Features:")
    print("‚úÖ Model Selection (Gemini/Llama)")
    print("‚úÖ SMA Web Intelligence")
    print("‚úÖ Multilingual Support (Arabic/French)")
    print("‚úÖ Real-time Response Generation")
    print("‚úÖ Source Attribution")
    print("‚úÖ Error Handling")

if __name__ == "__main__":
    main()
